{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6643c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1155d",
   "metadata": {},
   "source": [
    "#### Setup a model trained earlier that will decide if image contais layout or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a14bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(num_classes=2):\n",
    "    # Load pre-trained ResNet18\n",
    "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a632f",
   "metadata": {},
   "source": [
    "#### Function that will move images containing layout to filtered_images directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9789583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images(model, model_path='layout_classifier.pth', \n",
    "                            source_dir='data/raw',\n",
    "                            filtered_dir='data/filtered_images'):\n",
    "     \n",
    "     if isinstance(model, str):\n",
    "        try:\n",
    "            model, _ = setup_model() \n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "        except NameError:\n",
    "             print(\"Error: setup_model function not defined. Cannot load model from path.\")\n",
    "             return 0, 0\n",
    "        except FileNotFoundError:\n",
    "             print(f\"Error: Model file not found at {model_path}\")\n",
    "             return 0, 0\n",
    "     \n",
    "     model.eval()\n",
    "     device = next(model.parameters()).device\n",
    "\n",
    "     val_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "     \n",
    "     os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "     total_images = 0\n",
    "     filtered_images = 0\n",
    "\n",
    "     for source in os.listdir(source_dir):\n",
    "          source_path = os.path.join(source_dir, source)\n",
    "          if not os.path.isdir(source_path):\n",
    "               continue\n",
    "          for track in os.listdir(source_path):\n",
    "               track_path = os.path.join(source_path, track)\n",
    "               if not os.path.isdir(track_path):\n",
    "                    continue\n",
    "               os.makedirs(os.path.join(filtered_dir, track), exist_ok=True)\n",
    "\n",
    "               for img_name in os.listdir(track_path):\n",
    "                    img_path = os.path.join(track_path, img_name)\n",
    "                    total_images += 1\n",
    "\n",
    "                    try:\n",
    "                         img = Image.open(img_path).convert('RGB')\n",
    "                         img_tensor = val_transforms(img).unsqueeze(0).to(device)\n",
    "\n",
    "                         with torch.no_grad():\n",
    "                              output = model(img_tensor)\n",
    "                              _, predicted = torch.max(output, 1)\n",
    "                         \n",
    "                         if predicted.item() == 0:\n",
    "                              filtered_images += 1\n",
    "                              shutil.copy(img_path, os.path.join(filtered_dir, track, f'{source}_{img_name}'))\n",
    "                    except Exception as e:\n",
    "                         print(f\"Error processing image {img_path}: {e}\")\n",
    "                    \n",
    "     print(f\"\\nProcessing complete!\")\n",
    "     print(f\"Total images processed: {total_images}\")\n",
    "     print(f\"Images with layout: {filtered_images}\")\n",
    "     \n",
    "     if total_images > 0:\n",
    "          print(f\"Clean Images rate: {filtered_images/total_images*100:.1f}%\")\n",
    "     else:\n",
    "          print(\"Clean Images rate: N/A (No images processed)\")\n",
    "    \n",
    "     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8ec83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/3_ym9w5d05gbbkc5t4gh1kn80000gn/T/ipykernel_60347/3666995962.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/opt/anaconda3/envs/emotion-env/lib/python3.8/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image data/raw/google/Bahrain International Circuit/.DS_Store: cannot identify image file '/Users/bszczesniak/projekty/f1-layout-recognition/data/raw/google/Bahrain International Circuit/.DS_Store'\n",
      "\n",
      "Processing complete!\n",
      "Total images processed: 1369\n",
      "Images with layout: 1109\n",
      "Clean Images rate: 81.0%\n"
     ]
    }
   ],
   "source": [
    "filter_images('layout_classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6d36d",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "Model that 'cleans' data isn't perfect so it's still not the best, but for now this must work. In future, the feedback loop will help creating more realistic images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
