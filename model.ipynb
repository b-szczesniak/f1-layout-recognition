{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41dc7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e3650",
   "metadata": {},
   "source": [
    "#### Initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9086ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "filtered_data_dir = Path('data/filtered_images') \n",
    "batch_size = 32 \n",
    "img_size = 224\n",
    "learning_rate = 0.001\n",
    "num_epochs = 15 \n",
    "model_save_path = 'f1_track_layout_resnet18_v1.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc16c9",
   "metadata": {},
   "source": [
    "#### Setup image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363196bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9704ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "def get_dataloaders(data_dir, transforms_dict, batch_size=32, val_split=0.2):\n",
    "    # Create the full dataset with transform=None initially\n",
    "    full_dataset = CustomDataset(root=data_dir, transform=None)\n",
    "    \n",
    "    # Calculate sizes for train and validation splits\n",
    "    val_size = int(len(full_dataset) * val_split)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create datasets with appropriate transformations\n",
    "    train_dataset.dataset.transform = transforms_dict['train']\n",
    "    val_dataset.dataset.transform = transforms_dict['val']\n",
    "    \n",
    "    # Create and return dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafcd029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationDataModule:\n",
    "    \"\"\"\n",
    "    Data module for image classification tasks.\n",
    "    Handles data transforms, train/validation split, and DataLoader creation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        transform: Dict[str, transforms.Compose],\n",
    "        batch_size: int = 32,\n",
    "        val_split: float = 0.2,\n",
    "        image_size: Tuple[int, int] = (224, 224)\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.train_transforms = transform['train']\n",
    "        self.val_transforms = transform['val']\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        full_dataset = datasets.ImageFolder(root=self.data_dir)\n",
    "        total_samples = len(full_dataset)\n",
    "        val_size = int(total_samples * self.val_split)\n",
    "        train_size = total_samples - val_size\n",
    "\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        train_subset, val_subset = random_split(\n",
    "            full_dataset, [train_size, val_size], generator=generator\n",
    "        )\n",
    "\n",
    "        self.train_dataset = Subset(\n",
    "            datasets.ImageFolder(root=self.data_dir, transform=self.train_transforms),\n",
    "            train_subset.indices\n",
    "        )\n",
    "        self.val_dataset = Subset(\n",
    "            datasets.ImageFolder(root=self.data_dir, transform=self.val_transforms),\n",
    "            val_subset.indices\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Return DataLoader for training set.\"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise RuntimeError(\"Call setup() before train_dataloader().\")\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Return DataLoader for validation set.\"\"\"\n",
    "        if self.val_dataset is None:\n",
    "            raise RuntimeError(\"Call setup() before val_dataloader().\")\n",
    "        return DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 879\n",
      "Validation samples: 219\n",
      "Batch shape: torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "data_module = ImageClassificationDataModule(\n",
    "        data_dir='data/filtered_images',\n",
    "        transform=data_transforms,\n",
    "        batch_size=32,\n",
    "        val_split=0.2,\n",
    "        image_size=(224, 224)\n",
    "    )\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "\n",
    "print(f\"Train samples: {len(data_module.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(data_module.val_dataset)}\")\n",
    "\n",
    "# Iterate through one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e160d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Albert Park Circuit': 0, 'Autódromo Hermanos Rodríguez': 1, 'Bahrain International Circuit': 2, 'Baku City Circuit': 3, 'Circuit Gilles Villeneuve': 4, 'Circuit Zandvoort': 5, 'Circuit de Barcelona-Catalunya': 6, 'Circuit de Monaco': 7, 'Circuit de Spa-Francorchamps': 8, 'Circuit of the Americas': 9, 'Hungaroring': 10, 'Imola (Autodromo Enzo e Dino Ferrari)': 11, 'Interlagos (Autódromo José Carlos Pace)': 12, 'Jeddah Corniche Circuit': 13, 'Las Vegas Street Circuit': 14, 'Lusail International Circuit': 15, 'Marina Bay Street Circuit': 16, 'Miami International Autodrome': 17, 'Monza (Autodromo Nazionale Monza)': 18, 'Red Bull Ring': 19, 'Shanghai International Circuit': 20, 'Silverstone Circuit': 21, 'Suzuka International Racing Course': 22, 'Yas Marina Circuit': 23}\n",
      "{0: 'Albert Park Circuit', 1: 'Autódromo Hermanos Rodríguez', 2: 'Bahrain International Circuit', 3: 'Baku City Circuit', 4: 'Circuit Gilles Villeneuve', 5: 'Circuit Zandvoort', 6: 'Circuit de Barcelona-Catalunya', 7: 'Circuit de Monaco', 8: 'Circuit de Spa-Francorchamps', 9: 'Circuit of the Americas', 10: 'Hungaroring', 11: 'Imola (Autodromo Enzo e Dino Ferrari)', 12: 'Interlagos (Autódromo José Carlos Pace)', 13: 'Jeddah Corniche Circuit', 14: 'Las Vegas Street Circuit', 15: 'Lusail International Circuit', 16: 'Marina Bay Street Circuit', 17: 'Miami International Autodrome', 18: 'Monza (Autodromo Nazionale Monza)', 19: 'Red Bull Ring', 20: 'Shanghai International Circuit', 21: 'Silverstone Circuit', 22: 'Suzuka International Racing Course', 23: 'Yas Marina Circuit'}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = data_module.train_dataset.dataset.class_to_idx\n",
    "print(class_to_idx)\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bcbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
